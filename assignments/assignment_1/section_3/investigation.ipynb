{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:27.743916166Z",
     "start_time": "2023-09-19T17:28:52.460562287Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import gensim.downloader as api\n",
    "import gensim.models\n",
    "\n",
    "wiki_corpus = api.load('glove-wiki-gigaword-100')\n",
    "twitter_corpus = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def find_word(glove, a, b, x):\n",
    "    # NOTE: slightly different from the Lab3, but same base code\n",
    "    a = a.lower()\n",
    "    b = b.lower()\n",
    "    x = x.lower()\n",
    "    out = f\"> {a}:{b} as {x}:? \\n\"\n",
    "    top_words = glove.most_similar_cosmul(positive=[x, b], negative=[a], topn=20)\n",
    "    for num, (word, score) in enumerate(top_words):\n",
    "        out += f\"{num + 1}: ({score:.3f}) {word} \\n\"\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:27.747445386Z",
     "start_time": "2023-09-19T17:30:27.731612368Z"
    }
   },
   "id": "dc7dff5abc151c35"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def search_words(terms):\n",
    "    for word in terms:\n",
    "        try:\n",
    "            if type(word) in [list, tuple]:\n",
    "                print(\"Wiki:\", find_word(wiki_corpus, *word))\n",
    "                print(\"Twitter:\", find_word(twitter_corpus, *word))\n",
    "            else:\n",
    "                print(f\"---{word}---\")\n",
    "                print(\"Wiki: \" + str(wiki_corpus.most_similar(word, topn=20)))\n",
    "                print(\"Twitter: \" + str(twitter_corpus.most_similar(word, topn=20)))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:27.750260268Z",
     "start_time": "2023-09-19T17:30:27.737233753Z"
    }
   },
   "id": "c0d5eb717a78af25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What kind of biases are present in either dataset, if any?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a95c9c9598faf5a9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---man---\n",
      "Wiki: [('woman', 0.8323495388031006), ('boy', 0.7914870977401733), ('one', 0.7788748741149902), ('person', 0.7526815533638), ('another', 0.752223551273346), ('old', 0.7409117221832275), ('life', 0.737169623374939), ('father', 0.7370322346687317), ('turned', 0.7347695231437683), ('who', 0.734551191329956), ('whose', 0.7326126098632812), ('girl', 0.7291691303253174), ('he', 0.7255576252937317), ('him', 0.7238516807556152), ('young', 0.7218634486198425), ('himself', 0.7214202284812927), ('friend', 0.7170529961585999), ('once', 0.7132790684700012), ('being', 0.7123121023178101), ('a', 0.7093364000320435)]\n",
      "Twitter: [('boy', 0.7652449011802673), ('dude', 0.7523702383041382), ('guy', 0.7378775477409363), ('was', 0.7247804403305054), (\"'s\", 0.7206681966781616), ('bad', 0.7175806760787964), ('men', 0.7122883200645447), ('hell', 0.7033430337905884), ('shit', 0.7005720138549805), ('that', 0.695851743221283), ('is', 0.6952483654022217), ('he', 0.6951324343681335), ('but', 0.6918841004371643), ('god', 0.6912188529968262), ('way', 0.6850116848945618), ('mans', 0.6846962571144104), ('bet', 0.6839844584465027), ('kind', 0.6836308240890503), ('like', 0.6794912815093994), ('him', 0.6793851852416992)]\n",
      "---woman---\n",
      "Wiki: [('girl', 0.8472672700881958), ('man', 0.832349419593811), ('mother', 0.8275688290596008), ('boy', 0.7720510959625244), ('she', 0.7632068395614624), ('child', 0.7601761817932129), ('wife', 0.7505022883415222), ('her', 0.7445706129074097), ('herself', 0.7426273822784424), ('daughter', 0.726445734500885), ('victim', 0.7244972586631775), ('person', 0.7226606011390686), ('female', 0.7213833332061768), ('husband', 0.7211335897445679), ('pregnant', 0.7158757448196411), ('teenager', 0.7041847109794617), ('couple', 0.7007153034210205), ('women', 0.6860839128494263), ('old', 0.6820175051689148), ('young', 0.6819227933883667)]\n",
      "Twitter: [('women', 0.8050916790962219), ('girl', 0.797474205493927), ('wife', 0.7853385210037231), ('mother', 0.7815035581588745), ('person', 0.7773492932319641), ('female', 0.7678148150444031), ('guy', 0.7642642259597778), ('she', 0.7594019174575806), ('daughter', 0.740329921245575), ('child', 0.736954927444458), ('lady', 0.7349064350128174), ('every', 0.7299766540527344), ('husband', 0.726521909236908), ('father', 0.7210490107536316), ('who', 0.7187126874923706), ('knows', 0.715518057346344), ('does', 0.7127673625946045), ('chick', 0.7113626003265381), ('when', 0.7021607756614685), ('being', 0.7010672092437744)]\n",
      "---feminist---\n",
      "Wiki: [('feminism', 0.7527837157249451), ('feminists', 0.718891441822052), ('activism', 0.6536230444908142), ('activist', 0.6379612684249878), ('lesbian', 0.6358102560043335), ('humanist', 0.6227445006370544), ('modernist', 0.620481550693512), ('left-wing', 0.6202647089958191), ('postmodern', 0.6142586469650269), ('anarchist', 0.6133671998977661), ('literary', 0.5967345833778381), ('anti-pornography', 0.5946973562240601), ('antiwar', 0.5788055062294006), ('critique', 0.5770760774612427), ('anti-war', 0.5763559937477112), ('mainstream', 0.5761650800704956), ('humanistic', 0.5702264308929443), ('lgbt', 0.5684955716133118), ('advocate', 0.5666724443435669), ('libertarian', 0.5662504434585571)]\n",
      "Twitter: [('feminism', 0.7647305727005005), ('atheist', 0.7053334712982178), ('feminists', 0.691071093082428), ('liberal', 0.6902834177017212), ('conservative', 0.6791594624519348), ('religious', 0.6652476787567139), ('marxist', 0.6639546751976013), ('humanist', 0.645759105682373), ('sexist', 0.6401227712631226), ('sexism', 0.6397809982299805), ('bigot', 0.6395642161369324), ('right-wing', 0.6382970213890076), ('leftist', 0.6262497305870056), ('patriarchy', 0.6252223253250122), ('lgbt', 0.6248897910118103), ('extremist', 0.6243675351142883), ('socialist', 0.6229286789894104), ('political', 0.6222166419029236), ('elitist', 0.6173901557922363), ('misogynist', 0.6121279001235962)]\n",
      "Wiki: > european:white as asian:? \n",
      "1: (0.962) black \n",
      "2: (0.887) blue \n",
      "3: (0.869) gray \n",
      "4: (0.864) red \n",
      "5: (0.863) colored \n",
      "6: (0.855) brown \n",
      "7: (0.849) pink \n",
      "8: (0.844) purple \n",
      "9: (0.844) yellow \n",
      "10: (0.832) green \n",
      "11: (0.830) hispanic \n",
      "12: (0.827) spandex \n",
      "13: (0.827) whites \n",
      "14: (0.824) lendale \n",
      "15: (0.824) african \n",
      "16: (0.824) dark \n",
      "17: (0.821) collar \n",
      "18: (0.820) bright \n",
      "19: (0.819) pearl \n",
      "20: (0.817) cotton \n",
      "Twitter: > european:white as asian:? \n",
      "1: (1.036) girl \n",
      "2: (1.028) black \n",
      "3: (1.019) ugly \n",
      "4: (1.010) fat \n",
      "5: (1.009) cute \n",
      "6: (1.007) ass \n",
      "7: (0.999) skinny \n",
      "8: (0.998) chick \n",
      "9: (0.994) girls \n",
      "10: (0.983) guy \n",
      "11: (0.981) skinned \n",
      "12: (0.980) boy \n",
      "13: (0.978) chicks \n",
      "14: (0.977) sexy \n",
      "15: (0.975) tall \n",
      "16: (0.974) thick \n",
      "17: (0.970) lady \n",
      "18: (0.965) hot \n",
      "19: (0.964) dude \n",
      "20: (0.960) bitch \n",
      "\n",
      "Wiki: > man:jock as woman:? \n",
      "1: (0.792) pamelia \n",
      "2: (0.791) theodelinda \n",
      "3: (0.787) tonia \n",
      "4: (0.786) valborg \n",
      "5: (0.785) lydie \n",
      "6: (0.763) quivers \n",
      "7: (0.757) divorcee \n",
      "8: (0.755) wolsingham \n",
      "9: (0.753) margy \n",
      "10: (0.752) trudi \n",
      "11: (0.751) hettie \n",
      "12: (0.750) leanne \n",
      "13: (0.748) skyla \n",
      "14: (0.747) danelle \n",
      "15: (0.746) rosalie \n",
      "16: (0.746) garraud \n",
      "17: (0.745) esurance \n",
      "18: (0.744) lucienne \n",
      "19: (0.743) richeza \n",
      "20: (0.742) cécile \n",
      "\n",
      "Twitter: > man:jock as woman:? \n",
      "1: (1.010) voluptuous \n",
      "2: (0.948) boobed \n",
      "3: (0.942) متطرف \n",
      "4: (0.931) slutbucket \n",
      "5: (0.931) اختزال \n",
      "6: (0.925) headscarf \n",
      "7: (0.920) الخَيبہ \n",
      "8: (0.917) buxom \n",
      "9: (0.916) pigtails \n",
      "10: (0.915) curvy \n",
      "11: (0.914) pornstar \n",
      "12: (0.912) bigass \n",
      "13: (0.912) nnاسال \n",
      "14: (0.911) librarian \n",
      "15: (0.908) جامي \n",
      "16: (0.907) pdraig \n",
      "17: (0.907) backhandspring \n",
      "18: (0.904) girdle \n",
      "19: (0.903) koşul \n",
      "20: (0.903) كم_هو_مؤلم \n",
      "\n",
      "Wiki: > woman:cheerleader as man:? \n",
      "1: (0.825) nerd \n",
      "2: (0.813) recruiter \n",
      "3: (0.812) cheerleaders \n",
      "4: (0.810) geek \n",
      "5: (0.805) thug \n",
      "6: (0.800) lifer \n",
      "7: (0.799) standout \n",
      "8: (0.799) whiz \n",
      "9: (0.794) lineman \n",
      "10: (0.792) sidekick \n",
      "11: (0.792) defensive \n",
      "12: (0.790) dork \n",
      "13: (0.788) kid \n",
      "14: (0.786) jock \n",
      "15: (0.783) hoodlum \n",
      "16: (0.783) coach \n",
      "17: (0.783) ol' \n",
      "18: (0.782) linebackers \n",
      "19: (0.781) buddies \n",
      "20: (0.781) superstars \n",
      "\n",
      "Twitter: > woman:cheerleader as man:? \n",
      "1: (0.855) softball \n",
      "2: (0.853) aau \n",
      "3: (0.852) powderpuff \n",
      "4: (0.850) bball \n",
      "5: (0.846) baseball \n",
      "6: (0.844) basketball \n",
      "7: (0.841) volleyball \n",
      "8: (0.833) quarterback \n",
      "9: (0.827) vball \n",
      "10: (0.822) laker \n",
      "11: (0.821) varsity \n",
      "12: (0.814) lacrosse \n",
      "13: (0.814) fball \n",
      "14: (0.813) kicker \n",
      "15: (0.810) cheerleaders \n",
      "16: (0.810) player \n",
      "17: (0.809) cheerleading \n",
      "18: (0.806) soccer \n",
      "19: (0.804) allstar \n",
      "20: (0.803) hockey \n"
     ]
    }
   ],
   "source": [
    "search_words(['man', 'woman', 'feminist', ('european', 'white', 'asian'), ('man', 'jock', 'woman'), ('woman', 'cheerleader', 'man')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:30.110349609Z",
     "start_time": "2023-09-19T17:30:27.737562845Z"
    }
   },
   "id": "a7296358ad0b747b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Here we can see different biases present in the two corpora.\n",
    "- Man:\n",
    "   - Wikipedia: ageism \"old\"\n",
    "   - Twitter: discrimination \"bad\"/\"hell\"/\"shit\"\n",
    "- Woman:\n",
    "   - Wikipedia: Gender Stereotype \"mother\" 3rd result\n",
    "   - Twitter: Gender Stereotype \"mother\" 4th result \n",
    "- Feminist:\n",
    "   - Wikipedia: Sexual Orientation Bias \"lesbian\"\n",
    "- European : While = Asian : X\n",
    "   - Wikipedia: \"black\" (might be just \"overfitting\" due to color white association, also other output are colors)\n",
    "   - Twitter: Lookism \"ugly\"/\"fat\"\n",
    "- Man : Jock = Woman : X\n",
    "   - Twitter: Gender Bias \"slutbucket\" (perhaps the forced association \"Man: Jock\" messes up the output)\n",
    "- Woman : Cheerleader = Man : X\n",
    "   - Wikipedia: Stereotype \"nerd\"/\"geek\"\n",
    "\n",
    "In the Woman <-> Mother association is possible to see a human perspective\n",
    "The presented stereotypes show that Twitter, being community driven and less controlled then Wikipedia, presents more negative bias, for example the man discrimination or the gender bias for woman in relation with jock "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5312333baa7131e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Are there any differences with respect to bias between the two kinds of data?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93f71ffe3c63f92d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---party---\n",
      "Wiki: [('opposition', 0.8269407153129578), ('democratic', 0.8042268753051758), ('parties', 0.7943356037139893), ('coalition', 0.7723221182823181), ('leader', 0.7596955299377441), ('election', 0.7480783462524414), ('candidate', 0.746288537979126), ('liberal', 0.7460210919380188), ('socialist', 0.7336400151252747), ('conservative', 0.7326690554618835), ('elections', 0.7202402949333191), ('ruling', 0.7180086374282837), ('nationalist', 0.7169246077537537), ('leadership', 0.7141717076301575), ('political', 0.7107859253883362), ('communist', 0.7097721099853516), ('democrats', 0.7013227939605713), ('vote', 0.7007361650466919), ('bjp', 0.6920799612998962), ('candidates', 0.6906204223632812)]\n",
      "Twitter: [('saturday', 0.7777314186096191), ('friday', 0.7741458415985107), ('house', 0.7633090615272522), ('night', 0.7590202689170837), ('rave', 0.7588706016540527), ('parties', 0.7471879124641418), ('tonight', 0.741820216178894), ('next', 0.7226822376251221), ('coming', 0.7079103589057922), ('weekend', 0.7061418890953064), ('day', 0.7053808569908142), ('thursday', 0.7028266787528992), ('going', 0.6985507607460022), ('tomorrow', 0.6981012225151062), ('fun', 0.6969171166419983), ('sunday', 0.693480372428894), ('fest', 0.691654622554779), ('club', 0.689433753490448), ('vegas', 0.6859099864959717), ('monday', 0.6832247972488403)]\n",
      "---heroine---\n",
      "Wiki: [('protagonist', 0.6568334102630615), ('hero', 0.6362981796264648), ('heroines', 0.6277968287467957), ('character', 0.6071259379386902), ('villain', 0.596752405166626), ('lover', 0.5953372120857239), ('tale', 0.5798119306564331), ('actress', 0.5629972219467163), ('courtesan', 0.561911404132843), ('novel', 0.5593622326850891), ('portrayal', 0.5525379776954651), ('spunky', 0.5476809740066528), ('romance', 0.5452731847763062), ('protagonists', 0.5397405624389648), ('archetype', 0.5396749973297119), ('diva', 0.5373570322990417), ('woman', 0.5350012183189392), ('beloved', 0.5329294204711914), ('portrayed', 0.5316187739372253), ('plucky', 0.5303612351417542)]\n",
      "Twitter: [('heroin', 0.7222604751586914), ('cocaine', 0.6564655900001526), ('ecstasy', 0.640257716178894), ('meth', 0.6354444622993469), ('addict', 0.5963309407234192), ('herion', 0.5767630934715271), ('kareena', 0.5760515332221985), ('mdma', 0.5652492642402649), ('kapoor', 0.5584452152252197), ('ranbir', 0.5574559569358826), ('lsd', 0.5535504221916199), ('undead', 0.5523109436035156), ('pcp', 0.549814760684967), ('drug', 0.5474100708961487), ('ketamine', 0.5438587665557861), ('inject', 0.5384296774864197), ('fiend', 0.5345253944396973), ('addicts', 0.5323219299316406), ('villain', 0.5302015542984009), ('barfi', 0.5264550447463989)]\n",
      "---feet---\n",
      "Wiki: [('meters', 0.8185514807701111), ('metres', 0.7410042881965637), ('foot', 0.7329354882240295), ('above', 0.7076928615570068), ('tall', 0.7022892832756042), ('inches', 0.6933179497718811), ('height', 0.6796596050262451), ('beneath', 0.6783198714256287), ('meter', 0.6646437048912048), ('ft', 0.6452480554580688), ('below', 0.6420706510543823), ('cubic', 0.6414572596549988), ('around', 0.6333379149436951), ('floor', 0.6285281181335449), ('legs', 0.6241753101348877), ('miles', 0.6184850335121155), ('diameter', 0.6152980327606201), ('centimetres', 0.6117210388183594), ('centimeters', 0.6096634268760681), ('length', 0.6089832782745361)]\n",
      "Twitter: [('legs', 0.8345088958740234), ('toes', 0.8111957311630249), ('knees', 0.7701287269592285), ('hands', 0.7656199932098389), ('foot', 0.7491454482078552), ('ground', 0.7409893274307251), ('arms', 0.7353707551956177), ('head', 0.7334595918655396), ('balls', 0.7269718050956726), ('fingers', 0.7085915207862854), ('wet', 0.7003995180130005), ('chest', 0.6989226341247559), ('floor', 0.6947861909866333), ('butt', 0.6903678178787231), ('hole', 0.68672114610672), ('side', 0.6860136389732361), ('heads', 0.6853249669075012), ('arm', 0.6843756437301636), ('shoulders', 0.6823360323905945), ('stairs', 0.6810142397880554)]\n",
      "---assassin---\n",
      "Wiki: [('assassins', 0.7146174311637878), ('murderer', 0.6390713453292847), ('killers', 0.6111644506454468), ('traitor', 0.5964758396148682), ('killer', 0.5899376273155212), ('thief', 0.5718861222267151), ('accomplice', 0.5708957314491272), ('rabin', 0.5678818821907043), ('gunman', 0.5639756321907043), ('villain', 0.5619983077049255), ('robber', 0.556984007358551), ('hitman', 0.5550323128700256), ('assailant', 0.5450518131256104), ('kidnapper', 0.5380123257637024), ('henchmen', 0.5356395244598389), ('assassinated', 0.5295949578285217), ('would-be', 0.5276720523834229), ('yigal', 0.5246502757072449), ('stalker', 0.5223767757415771), ('rapist', 0.5144772529602051)]\n",
      "Twitter: [('creed', 0.8661605715751648), ('assassins', 0.8398395776748657), ('dishonored', 0.794792890548706), ('assasin', 0.771339476108551), ('tomb', 0.7504222393035889), ('skyrim', 0.750066876411438), ('hitman', 0.7455872893333435), ('battlefield', 0.7367081046104431), ('darksiders', 0.7300786972045898), ('bioshock', 0.7276681661605835), ('borderlands', 0.7209414839744568), ('crysis', 0.7188465595245361), ('arkham', 0.7140955924987793), ('dlc', 0.6948183178901672), ('kombat', 0.6913812756538391), ('raider', 0.690127968788147), ('gameplay', 0.6852818727493286), ('resident', 0.6847484111785889), ('tekken', 0.6834316253662109), ('ubisoft', 0.6753928661346436)]\n",
      "---us---\n",
      "Wiki: [('u.s.', 0.8688446283340454), ('about', 0.7225258946418762), ('u.s', 0.7174392938613892), ('up', 0.7140861749649048), ('than', 0.7109500169754028), ('american', 0.7098500728607178), ('united', 0.6898850202560425), ('more', 0.6826522946357727), ('iraq', 0.6783517003059387), ('americans', 0.6752436757087708), ('to', 0.6751635670661926), ('over', 0.673871636390686), ('week', 0.6727799773216248), ('dollars', 0.6723083257675171), ('last', 0.6688793301582336), ('states', 0.6675779819488525), ('say', 0.6661688089370728), ('come', 0.6634399890899658), ('if', 0.6609610319137573), ('now', 0.6609418988227844)]\n",
      "Twitter: [('them', 0.8468600511550903), ('our', 0.8370324969291687), ('will', 0.8334304094314575), ('for', 0.8257209658622742), ('other', 0.8248641490936279), ('bring', 0.8213719725608826), ('the', 0.817555844783783), ('see', 0.8156278133392334), ('there', 0.8154054284095764), ('any', 0.8136047124862671), ('to', 0.8075667023658752), ('all', 0.8074207305908203), ('give', 0.807338535785675), ('from', 0.8065269589424133), ('let', 0.8048815727233887), ('you', 0.8044819831848145), ('people', 0.8040902614593506), ('it', 0.8007140159606934), ('those', 0.8006559014320374), ('him', 0.7994582653045654)]\n",
      "---rip---\n",
      "Wiki: [('ripping', 0.5810015201568604), ('ripped', 0.5470159649848938), ('rattle', 0.532099187374115), ('suck', 0.5307959318161011), ('rips', 0.5275321006774902), ('tearing', 0.5266213417053223), ('shove', 0.523918628692627), ('curl', 0.523154616355896), ('shake', 0.520952582359314), ('tore', 0.519932746887207), ('lash', 0.5186267495155334), ('blown', 0.518498420715332), ('bleed', 0.5040979981422424), ('pull', 0.49424389004707336), ('roll', 0.49111685156822205), ('blow', 0.4864518642425537), ('loose', 0.4852427542209625), ('plug', 0.48006391525268555), ('yank', 0.47884127497673035), ('surf', 0.47872161865234375)]\n",
      "Twitter: [('r.i.p', 0.8857602477073669), ('r.i.p.', 0.8423160314559937), ('nelson', 0.7369442582130432), ('paul', 0.6931714415550232), ('walker', 0.6914694309234619), ('mandela', 0.671409010887146), ('died', 0.6713599562644958), ('whitney', 0.6607978940010071), ('legend', 0.6523450016975403), ('uncle', 0.6471095085144043), ('tribute', 0.6423582434654236), ('aka', 0.6405697464942932), ('jackson', 0.6346625685691833), ('brian', 0.6316938400268555), ('mj', 0.6303181648254395), ('brother', 0.6302072405815125), ('michael', 0.6250395774841309), ('grandpa', 0.622800886631012), ('father', 0.6161565780639648), ('tony', 0.6148844957351685)]\n"
     ]
    }
   ],
   "source": [
    "search_words(['party', 'heroine', 'feet', 'assassin', 'us', 'rip'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:30.556869209Z",
     "start_time": "2023-09-19T17:30:30.046963620Z"
    }
   },
   "id": "393669fe948868d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Here we can see a difference between the twitter and the wikipedia corpora.\n",
    "- Party:\n",
    "   - Wikipedia: election party\n",
    "   - Twitter: fun event\n",
    "- Heroine:\n",
    "   - Wikipedia: comic/movies hero\n",
    "   - Twitter: drug\n",
    "- Feet:\n",
    "   - Wikipedia: measure\n",
    "   - Twitter: body part\n",
    "- Assassin:\n",
    "   - Wikipedia: killer\n",
    "   - Twitter: video games\n",
    "- US:\n",
    "   - Wikipedia: country\n",
    "   - Twitter: pronoun\n",
    "- RIP:\n",
    "   - Wikipedia: tearing apart\n",
    "   - Twitter: death\n",
    " \n",
    "Wikipedia seems more data driven, is visible that the main purpose is to transfer knowledge.\n",
    " Twitter seems more user driven, is visible that the main purpose is to communicate with other users and present a personal point of view."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6959a78893ff2feb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Can biases between concepts be revealed trough visualization?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66ffc2243fc1717e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "\n",
    "def extract_word_vectors(word_list: list[str], corpus: gensim.models.KeyedVectors):\n",
    "    word_vectors = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            word_vectors.append(corpus[word])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return word_list, word_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T17:30:30.590202495Z",
     "start_time": "2023-09-19T17:30:30.544056128Z"
    }
   },
   "id": "aaa27bdb450518db"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def save_word_vector_for_visualisation(word_list: list[str], word_vectors: list[list[float]], output_path: str):\n",
    "    word_vector = gensim.models.KeyedVectors(vector_size=100)\n",
    "    word_vector.add_vectors(word_list, word_vectors)\n",
    "    if not os.path.exists(output_path) or not os.path.isdir(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    word_vector.save_word2vec_format(output_path + '/word_vector.txt', binary=False)\n",
    "    ! python -m gensim.scripts.word2vec2tensor --input {output_path}/word_vector.txt --output {output_path}/word_vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T18:08:09.936981379Z",
     "start_time": "2023-09-19T18:08:09.890826192Z"
    }
   },
   "id": "308156051599460b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-19 20:09:59,303 - word2vec2tensor - INFO - running /home/administrator/Desktop/T-725-MALV-Natural-Language-Processing/assignments/assignment_1/venv/lib/python3.10/site-packages/gensim/scripts/word2vec2tensor.py --input ./output/wiki_output/word_vector.txt --output ./output/wiki_output/word_vector\r\n",
      "2023-09-19 20:09:59,303 - keyedvectors - INFO - loading projection weights from ./output/wiki_output/word_vector.txt\r\n",
      "2023-09-19 20:09:59,306 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (8, 100) matrix of type float32 from ./output/wiki_output/word_vector.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-09-19T20:09:59.304736', 'gensim': '4.3.2', 'python': '3.10.13 (main, Aug 25 2023, 13:20:03) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-163-generic-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}\r\n",
      "2023-09-19 20:09:59,310 - word2vec2tensor - INFO - 2D tensor file saved to ./output/wiki_output/word_vector_tensor.tsv\r\n",
      "2023-09-19 20:09:59,311 - word2vec2tensor - INFO - Tensor metadata file saved to ./output/wiki_output/word_vector_metadata.tsv\r\n",
      "2023-09-19 20:09:59,311 - word2vec2tensor - INFO - finished running word2vec2tensor.py\r\n",
      "2023-09-19 20:10:00,238 - word2vec2tensor - INFO - running /home/administrator/Desktop/T-725-MALV-Natural-Language-Processing/assignments/assignment_1/venv/lib/python3.10/site-packages/gensim/scripts/word2vec2tensor.py --input ./output/twitter_output/word_vector.txt --output ./output/twitter_output/word_vector\r\n",
      "2023-09-19 20:10:00,239 - keyedvectors - INFO - loading projection weights from ./output/twitter_output/word_vector.txt\r\n",
      "2023-09-19 20:10:00,241 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (8, 100) matrix of type float32 from ./output/twitter_output/word_vector.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-09-19T20:10:00.239883', 'gensim': '4.3.2', 'python': '3.10.13 (main, Aug 25 2023, 13:20:03) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-163-generic-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}\r\n",
      "2023-09-19 20:10:00,242 - word2vec2tensor - INFO - 2D tensor file saved to ./output/twitter_output/word_vector_tensor.tsv\r\n",
      "2023-09-19 20:10:00,242 - word2vec2tensor - INFO - Tensor metadata file saved to ./output/twitter_output/word_vector_metadata.tsv\r\n",
      "2023-09-19 20:10:00,242 - word2vec2tensor - INFO - finished running word2vec2tensor.py\r\n"
     ]
    }
   ],
   "source": [
    "sample_word_list, sample_word_vectors = extract_word_vectors(['pilot', 'teacher', 'surgeon', 'babysitter', 'engineer', 'hairdresser', 'man', 'woman'], wiki_corpus)\n",
    "save_word_vector_for_visualisation(sample_word_list, sample_word_vectors, './output/wiki_output')\n",
    "sample_word_list, sample_word_vectors = extract_word_vectors(['pilot', 'teacher', 'surgeon', 'babysitter', 'engineer', 'hairdresser', 'man', 'woman'], twitter_corpus)\n",
    "save_word_vector_for_visualisation(sample_word_list, sample_word_vectors, './output/twitter_output')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T18:10:00.459849054Z",
     "start_time": "2023-09-19T18:09:58.261949091Z"
    }
   },
   "id": "68d43fe79b2ca51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think visualisation can help in finding some biases, but it's not a definitive solution.\n",
    "I tried using [https://projector.tensorflow.org](https://projector.tensorflow.org) and I found some interesting results.\n",
    "By inputting some gender-biased words, the plot shows clearly two areas, with a large margin and \"male\" and \"female\" usable as support vectors for defining a margin in an SVM like fashion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d655c6fb6b217c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Can bias in word embeddings be removed? if so, how?\n",
    "\n",
    "In my opinion is not possible or at least it is non-trivial to remove completely bias in word embeddings.\n",
    "The main reason is that bias are part of the human thought process that is reflected in the text corpus.\n",
    "And the word vectors are extracted analysing the text corpus.\n",
    "\n",
    "Bias can also be seen as a way humans have to separate, logically connect and differentiate concepts.\n",
    "For example, a basket ball and the planet are two different concepts, but is possible to logically relate both of them to a sphere.\n",
    "This duality may be reflected in a word2vec approach, where, depending on the corpus used for training, a sphere may be more near to either a ball or a planet.\n",
    "\n",
    "Also, is necessary to differentiate between positive and negative bias from a human perspective.\n",
    "A positive bias can be something similar to the sphere <-> ball/planet relation, it is indeed unharmful and can be useful to explain and understand concepts.\n",
    "A negative bias can be the \"ugly\"/\"fat\" or the \"bad\"/\"hell\" relation presented before.\n",
    "\n",
    "In my opinion, the only way to completely remove bias is to remove the human factor from the text corpus, which is not possible due to the nature of the text corpus itself.\n",
    "Is arguable that AI generated text corpora are not generated by humans, but the AI is trained on human generated text corpora, so the human factor may still be present.\n",
    "\n",
    "I think, the bias can be lowered by using a more general or large text corpus, for example by using a text corpus that is not language specific, like the [Universal Dependencies](https://universaldependencies.org/).\n",
    "Also, the bias can be lowered by analysing the generated model and mitigating the obtained results, just like the work performed by the OpenAI engineers, that created specific datasets to lower any bias and points of view from the GPT model.\n",
    "Finally, a more mathematical way to approach the problem, is by creating a neutral vector and use it to identify the bias, then, by using the bias vector, is possible to remove the bias from the model.\n",
    "Is important to notice that this behaviour may lead to a loss of information.\n",
    "For example, words like \"father\" and \"mother\" if the gender is perceived as a bias, can be de-biased and the resulting vector may be something similar to \"parent\".\n",
    "This way, the gender bias will be removed, but also the meaning of the word will change.\n",
    "The change described may improve the results by lowering the presence of bias, but may eventually lead to other problems, like inconsistencies or incongruences in the model.\n",
    "Therefore, the mathematical approach to a vector normalisation or de-biasing, has to be performed following some criterion in order to decide which words have to remain biased, and which words have to be neutral, thus leaving some \"wanted\" bias."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f70de581379468"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
